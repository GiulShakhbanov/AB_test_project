{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1da770902e9be5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T14:56:11.542942Z",
     "start_time": "2025-12-11T14:56:11.506505Z"
    }
   },
   "outputs": [],
   "source": [
    "# Раздел 1. Импорт библиотек и конфигурация путей\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "DATA_DIR = Path(\"data/raw\")\n",
    "OUTPUT_DIR = Path(\"outputs\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "REQUIRED_FILES = [\n",
    "    \"Money.csv\",\n",
    "    \"Cash.csv\",\n",
    "    \"ABgroup.csv\",\n",
    "    \"Platforms.csv\",\n",
    "    \"Cheaters.csv\",\n",
    "]\n",
    "\n",
    "if not DATA_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Каталог с данными не найден: {DATA_DIR.absolute()}\")\n",
    "\n",
    "missing_files = [fname for fname in REQUIRED_FILES if not (DATA_DIR / fname).exists()]\n",
    "if missing_files:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Не найдены исходники: {', '.join(missing_files)} в {DATA_DIR.absolute()}\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6edcfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DQ] Сводка сохранена в outputs/dq_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Раздел 2. Загрузка данных и Data Quality\n",
    "def load_money(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Загружает платежи, не парся даты на этапе read_csv.\"\"\"\n",
    "    df = pd.read_csv(path, dtype={\"user_id\": \"string\"}, na_values=[\"\", \" \"])\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%d.%m.%Y\", errors=\"coerce\")\n",
    "    df[\"money\"] = pd.to_numeric(df[\"money\"], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_cash(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Загружает траты внутриигровой валюты.\"\"\"\n",
    "    df = pd.read_csv(path, dtype={\"user_id\": \"string\"}, na_values=[\"\", \" \"])\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%d.%m.%Y\", errors=\"coerce\")\n",
    "    df[\"cash\"] = pd.to_numeric(df[\"cash\"], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_abgroup(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Загружает распределение по группам эксперимента.\"\"\"\n",
    "    return pd.read_csv(path, dtype={\"user_id\": \"string\", \"group\": \"string\"})\n",
    "\n",
    "\n",
    "def load_platforms(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Загружает платформу пользователя.\"\"\"\n",
    "    return pd.read_csv(path, dtype={\"user_id\": \"string\", \"platform\": \"string\"})\n",
    "\n",
    "\n",
    "def load_cheaters(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Загружает список явных читеров.\"\"\"\n",
    "    df = pd.read_csv(path, dtype={\"user_id\": \"string\"})\n",
    "    df[\"cheaters\"] = pd.to_numeric(df[\"cheaters\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "def dq_stats_transactions(df: pd.DataFrame, value_col: str, table: str) -> Dict[str, float]:\n",
    "    \"\"\"Формирует метрики качества для транзакционных таблиц.\"\"\"\n",
    "    return {\n",
    "        \"table\": table,\n",
    "        \"rows\": int(df.shape[0]),\n",
    "        \"cols\": int(df.shape[1]),\n",
    "        \"share_nat_date\": float(df[\"date\"].isna().mean()),\n",
    "        \"share_nan_user_id\": float(df[\"user_id\"].isna().mean()),\n",
    "        \"negative_value_count\": int((df[value_col] < 0).sum()),\n",
    "        \"duplicate_keys\": np.nan,\n",
    "    }\n",
    "\n",
    "\n",
    "def dq_stats_user_level(df: pd.DataFrame, table: str) -> Dict[str, float]:\n",
    "    \"\"\"Формирует метрики качества для пользовательских таблиц.\"\"\"\n",
    "    return {\n",
    "        \"table\": table,\n",
    "        \"rows\": int(df.shape[0]),\n",
    "        \"cols\": int(df.shape[1]),\n",
    "        \"share_nat_date\": np.nan,\n",
    "        \"share_nan_user_id\": float(df[\"user_id\"].isna().mean()),\n",
    "        \"negative_value_count\": np.nan,\n",
    "        \"duplicate_keys\": int(df[\"user_id\"].duplicated().sum()),\n",
    "    }\n",
    "\n",
    "\n",
    "money_df = load_money(DATA_DIR / \"Money.csv\")\n",
    "cash_df = load_cash(DATA_DIR / \"Cash.csv\")\n",
    "ab_group_df = load_abgroup(DATA_DIR / \"ABgroup.csv\")\n",
    "platforms_df = load_platforms(DATA_DIR / \"Platforms.csv\")\n",
    "cheaters_df = load_cheaters(DATA_DIR / \"Cheaters.csv\")\n",
    "\n",
    "dq_records = [\n",
    "    dq_stats_transactions(money_df, \"money\", \"Money\"),\n",
    "    dq_stats_transactions(cash_df, \"cash\", \"Cash\"),\n",
    "    dq_stats_user_level(ab_group_df, \"ABgroup\"),\n",
    "    dq_stats_user_level(platforms_df, \"Platforms\"),\n",
    "    dq_stats_user_level(cheaters_df, \"Cheaters\"),\n",
    "]\n",
    "\n",
    "dq_summary = pd.DataFrame(dq_records)\n",
    "dq_summary_path = OUTPUT_DIR / \"dq_summary.csv\"\n",
    "dq_summary.to_csv(dq_summary_path, index=False)\n",
    "print(f\"[DQ] Сводка сохранена в {dq_summary_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffe062ed2308e972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cheaters] Явные читеры: 353\n",
      "[Cheaters] Высокий total_cash при низком total_money: 697 (порог cash ≥ 10900.00, money ≤ 1.0)\n",
      "[Cheaters] Экстремальные max_daily_cash: 1125 (порог cash_day ≥ 6700.00)\n",
      "[Cheaters] Чистых пользователей после фильтров: 1078875\n"
     ]
    }
   ],
   "source": [
    "# Раздел 3. Детект читеров\n",
    "def sanitize_transaction_df(df: pd.DataFrame, value_col: str) -> pd.DataFrame:\n",
    "    \"\"\"Удаляет строки с пустыми user_id, некорректными датами и отрицательными значениями.\"\"\"\n",
    "    clean_df = df.dropna(subset=[\"user_id\", \"date\"]).copy()\n",
    "    clean_df = clean_df[clean_df[value_col] >= 0]\n",
    "    return clean_df\n",
    "\n",
    "\n",
    "def deduplicate_dimension(df: pd.DataFrame, value_col: str) -> pd.DataFrame:\n",
    "    \"\"\"Удаляет строки без user_id и оставляет по одному значению на пользователя.\"\"\"\n",
    "    clean_df = df.dropna(subset=[\"user_id\"]).copy()\n",
    "    clean_df[\"user_id\"] = clean_df[\"user_id\"].astype(\"string\")\n",
    "    return clean_df.drop_duplicates(subset=[\"user_id\"], keep=\"last\")\n",
    "\n",
    "\n",
    "money_clean = sanitize_transaction_df(money_df, \"money\")\n",
    "cash_clean = sanitize_transaction_df(cash_df, \"cash\")\n",
    "ab_group_clean = deduplicate_dimension(ab_group_df, \"group\")\n",
    "platforms_clean = deduplicate_dimension(platforms_df, \"platform\")\n",
    "cheaters_clean = deduplicate_dimension(cheaters_df, \"cheaters\")\n",
    "\n",
    "money_daily = (\n",
    "    money_clean.groupby([\"user_id\", \"date\"], as_index=False)[\"money\"]\n",
    "    .sum()\n",
    "    .rename(columns={\"money\": \"money_day\"})\n",
    ")\n",
    "cash_daily = (\n",
    "    cash_clean.groupby([\"user_id\", \"date\"], as_index=False)[\"cash\"]\n",
    "    .sum()\n",
    "    .rename(columns={\"cash\": \"cash_day\"})\n",
    ")\n",
    "\n",
    "money_user = (\n",
    "    money_daily.groupby(\"user_id\", as_index=False)\n",
    "    .agg(total_revenue=(\"money_day\", \"sum\"), days_with_payments=(\"date\", \"nunique\"))\n",
    ")\n",
    "cash_user = (\n",
    "    cash_daily.groupby(\"user_id\", as_index=False)\n",
    "    .agg(\n",
    "        total_cash=(\"cash_day\", \"sum\"),\n",
    "        max_daily_cash=(\"cash_day\", \"max\"),\n",
    "        days_with_cash=(\"date\", \"nunique\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "cheater_base = (\n",
    "    ab_group_clean[[\"user_id\"]]\n",
    "    .merge(money_user, on=\"user_id\", how=\"left\")\n",
    "    .merge(cash_user, on=\"user_id\", how=\"left\")\n",
    ")\n",
    "for col in [\"total_revenue\", \"days_with_payments\", \"total_cash\", \"max_daily_cash\", \"days_with_cash\"]:\n",
    "    if col in cheater_base:\n",
    "        cheater_base[col] = cheater_base[col].fillna(0)\n",
    "\n",
    "CHEATER_RULES: Dict[str, float] = {\n",
    "    \"cash_quantile\": 0.999,\n",
    "    \"money_threshold\": 1.0,\n",
    "    \"max_daily_cash_quantile\": 0.999,\n",
    "}\n",
    "\n",
    "cash_threshold = (\n",
    "    cheater_base[\"total_cash\"].quantile(CHEATER_RULES[\"cash_quantile\"])\n",
    "    if not cheater_base[\"total_cash\"].empty\n",
    "    else np.inf\n",
    ")\n",
    "max_daily_cash_threshold = (\n",
    "    cheater_base[\"max_daily_cash\"].quantile(CHEATER_RULES[\"max_daily_cash_quantile\"])\n",
    "    if not cheater_base[\"max_daily_cash\"].empty\n",
    "    else np.inf\n",
    ")\n",
    "\n",
    "explicit_cheaters = set(\n",
    "    cheaters_clean.loc[cheaters_clean[\"cheaters\"] == 1, \"user_id\"].dropna().astype(str)\n",
    ")\n",
    "high_cash_low_money = set(\n",
    "    cheater_base.loc[\n",
    "        (cheater_base[\"total_cash\"] >= cash_threshold)\n",
    "        & (cheater_base[\"total_revenue\"] <= CHEATER_RULES[\"money_threshold\"]),\n",
    "        \"user_id\",\n",
    "    ].astype(str)\n",
    ")\n",
    "extreme_daily_cash = set(\n",
    "    cheater_base.loc[cheater_base[\"max_daily_cash\"] >= max_daily_cash_threshold, \"user_id\"].astype(str)\n",
    ")\n",
    "\n",
    "print(f\"[Cheaters] Явные читеры: {len(explicit_cheaters)}\")\n",
    "print(\n",
    "    \"[Cheaters] Высокий total_cash при низком total_money: \"\n",
    "    f\"{len(high_cash_low_money)} (порог cash ≥ {cash_threshold:.2f}, money ≤ {CHEATER_RULES['money_threshold']})\"\n",
    ")\n",
    "print(\n",
    "    \"[Cheaters] Экстремальные max_daily_cash: \"\n",
    "    f\"{len(extreme_daily_cash)} (порог cash_day ≥ {max_daily_cash_threshold:.2f})\"\n",
    ")\n",
    "\n",
    "all_user_ids = pd.Index(ab_group_clean[\"user_id\"].dropna().astype(str).unique())\n",
    "all_user_ids = all_user_ids.union(pd.Index(list(explicit_cheaters)))\n",
    "\n",
    "cheater_flags = pd.DataFrame({\"user_id\": all_user_ids})\n",
    "cheater_flags[\"explicit_cheater\"] = cheater_flags[\"user_id\"].isin(explicit_cheaters)\n",
    "cheater_flags[\"rule_high_cash_low_revenue\"] = cheater_flags[\"user_id\"].isin(high_cash_low_money)\n",
    "cheater_flags[\"rule_extreme_daily_cash\"] = cheater_flags[\"user_id\"].isin(extreme_daily_cash)\n",
    "cheater_flags[\"any_cheater_flag\"] = cheater_flags[\n",
    "    [\"explicit_cheater\", \"rule_high_cash_low_revenue\", \"rule_extreme_daily_cash\"]\n",
    "].any(axis=1)\n",
    "\n",
    "clean_users = set(\n",
    "    cheater_flags.loc[~cheater_flags[\"any_cheater_flag\"], \"user_id\"].astype(str)\n",
    ")\n",
    "print(f\"[Cheaters] Чистых пользователей после фильтров: {len(clean_users)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "008148b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Раздел 4. Аналитический датасет\n",
    "daily_merged = pd.merge(money_daily, cash_daily, on=[\"user_id\", \"date\"], how=\"outer\")\n",
    "daily_merged[\"money_day\"] = daily_merged[\"money_day\"].fillna(0)\n",
    "daily_merged[\"cash_day\"] = daily_merged[\"cash_day\"].fillna(0)\n",
    "\n",
    "daily_dataset = (\n",
    "    daily_merged.merge(ab_group_clean, on=\"user_id\", how=\"inner\")\n",
    "    .merge(platforms_clean, on=\"user_id\", how=\"left\")\n",
    ")\n",
    "daily_dataset[\"platform\"] = daily_dataset[\"platform\"].fillna(\"Unknown\")\n",
    "daily_dataset = daily_dataset[daily_dataset[\"user_id\"].isin(clean_users)].copy()\n",
    "\n",
    "user_level_agg = (\n",
    "    daily_dataset.groupby(\"user_id\", as_index=False)\n",
    "    .agg(total_revenue=(\"money_day\", \"sum\"), total_cash=(\"cash_day\", \"sum\"))\n",
    ")\n",
    "\n",
    "user_level = (\n",
    "    ab_group_clean.merge(platforms_clean, on=\"user_id\", how=\"left\")\n",
    "    .merge(user_level_agg, on=\"user_id\", how=\"left\")\n",
    ")\n",
    "user_level[\"platform\"] = user_level[\"platform\"].fillna(\"Unknown\")\n",
    "user_level[\"total_revenue\"] = user_level[\"total_revenue\"].fillna(0)\n",
    "user_level[\"total_cash\"] = user_level[\"total_cash\"].fillna(0)\n",
    "user_level = user_level[user_level[\"user_id\"].isin(clean_users)].copy()\n",
    "user_level[\"is_payer\"] = user_level[\"total_revenue\"] > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bf5010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Раздел 5. Метрики и доверительные интервалы\n",
    "def aggregate_metrics(df: pd.DataFrame, group_cols: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"Считает ARPU, ARPPU и cash_per_user для переданных группировок.\"\"\"\n",
    "    grouped = (\n",
    "        df.groupby(group_cols, dropna=False)\n",
    "        .agg(\n",
    "            total_revenue=(\"money_day\", \"sum\"),\n",
    "            total_cash=(\"cash_day\", \"sum\"),\n",
    "            user_count=(\"user_id\", pd.Series.nunique),\n",
    "            payer_count=(\"money_day\", lambda x: (x > 0).sum()),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    grouped[\"arpu\"] = grouped[\"total_revenue\"] / grouped[\"user_count\"].replace(0, np.nan)\n",
    "    grouped[\"arppu\"] = grouped[\"total_revenue\"] / grouped[\"payer_count\"].replace(0, np.nan)\n",
    "    grouped[\"cash_per_user\"] = grouped[\"total_cash\"] / grouped[\"user_count\"].replace(0, np.nan)\n",
    "    return grouped\n",
    "\n",
    "\n",
    "metrics_daily = aggregate_metrics(\n",
    "    daily_dataset, [\"date\", \"group\", \"platform\"]\n",
    ").sort_values([\"date\", \"group\", \"platform\"])\n",
    "\n",
    "metrics_total = (\n",
    "    user_level.groupby([\"group\", \"platform\"], dropna=False)\n",
    "    .agg(\n",
    "        total_revenue=(\"total_revenue\", \"sum\"),\n",
    "        total_cash=(\"total_cash\", \"sum\"),\n",
    "        user_count=(\"user_id\", pd.Series.nunique),\n",
    "        payer_count=(\"is_payer\", \"sum\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "metrics_total[\"arpu\"] = metrics_total[\"total_revenue\"] / metrics_total[\"user_count\"].replace(0, np.nan)\n",
    "metrics_total[\"arppu\"] = metrics_total[\"total_revenue\"] / metrics_total[\"payer_count\"].replace(0, np.nan)\n",
    "metrics_total[\"cash_per_user\"] = metrics_total[\"total_cash\"] / metrics_total[\"user_count\"].replace(0, np.nan)\n",
    "\n",
    "\n",
    "def mean_confidence_interval(series: pd.Series, alpha: float = 0.05) -> Tuple[float, float]:\n",
    "    \"\"\"Возвращает границы t-интервала для среднего.\"\"\"\n",
    "    clean_series = series.dropna()\n",
    "    n = clean_series.shape[0]\n",
    "    if n == 0:\n",
    "        return (np.nan, np.nan)\n",
    "    if n == 1:\n",
    "        mean_val = float(clean_series.iloc[0])\n",
    "        return (mean_val, mean_val)\n",
    "    mean_val = float(clean_series.mean())\n",
    "    se = float(clean_series.std(ddof=1) / np.sqrt(n))\n",
    "    delta = stats.t.ppf(1 - alpha / 2, df=n - 1) * se\n",
    "    return (mean_val - delta, mean_val + delta)\n",
    "\n",
    "\n",
    "ci_records: List[Dict[str, object]] = []\n",
    "for (group_value, platform_value), subset in user_level.groupby([\"group\", \"platform\"], dropna=False):\n",
    "    arpu_series = subset[\"total_revenue\"]\n",
    "    cash_series = subset[\"total_cash\"]\n",
    "    payers_series = subset.loc[subset[\"is_payer\"], \"total_revenue\"]\n",
    "    arpu_lower, arpu_upper = mean_confidence_interval(arpu_series)\n",
    "    cash_lower, cash_upper = mean_confidence_interval(cash_series)\n",
    "    arppu_lower, arppu_upper = mean_confidence_interval(payers_series)\n",
    "    ci_records.extend(\n",
    "        [\n",
    "            {\n",
    "                \"group\": group_value,\n",
    "                \"platform\": platform_value,\n",
    "                \"metric\": \"arpu\",\n",
    "                \"mean\": float(arpu_series.mean()),\n",
    "                \"ci_lower\": arpu_lower,\n",
    "                \"ci_upper\": arpu_upper,\n",
    "                \"n\": int(arpu_series.shape[0]),\n",
    "            },\n",
    "            {\n",
    "                \"group\": group_value,\n",
    "                \"platform\": platform_value,\n",
    "                \"metric\": \"cash_per_user\",\n",
    "                \"mean\": float(cash_series.mean()),\n",
    "                \"ci_lower\": cash_lower,\n",
    "                \"ci_upper\": cash_upper,\n",
    "                \"n\": int(cash_series.shape[0]),\n",
    "            },\n",
    "            {\n",
    "                \"group\": group_value,\n",
    "                \"platform\": platform_value,\n",
    "                \"metric\": \"arppu\",\n",
    "                \"mean\": float(payers_series.mean()) if not payers_series.empty else np.nan,\n",
    "                \"ci_lower\": arppu_lower,\n",
    "                \"ci_upper\": arppu_upper,\n",
    "                \"n\": int(payers_series.shape[0]),\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "\n",
    "metrics_ci = pd.DataFrame(ci_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f673c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Export] metrics_daily → outputs/metrics_daily.csv\n",
      "[Export] metrics_total → outputs/metrics_total.csv\n",
      "[Export] metrics_ci → outputs/metrics_ci.csv\n",
      "[Export] user_level_clean → outputs/user_level_clean.csv\n",
      "[Export] ARPU/ARPPU_by_group_platform.xlsx → outputs/ARPU_by_group_platform.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Раздел 6. Экспорт\n",
    "metrics_daily_path = OUTPUT_DIR / \"metrics_daily.csv\"\n",
    "metrics_total_path = OUTPUT_DIR / \"metrics_total.csv\"\n",
    "metrics_ci_path = OUTPUT_DIR / \"metrics_ci.csv\"\n",
    "user_level_path = OUTPUT_DIR / \"user_level_clean.csv\"\n",
    "excel_path = OUTPUT_DIR / \"ARPU_by_group_platform.xlsx\"\n",
    "\n",
    "metrics_daily.to_csv(metrics_daily_path, index=False)\n",
    "metrics_total.to_csv(metrics_total_path, index=False)\n",
    "metrics_ci.to_csv(metrics_ci_path, index=False)\n",
    "user_level.to_csv(user_level_path, index=False)\n",
    "\n",
    "arpu_pivot = metrics_total.pivot(index=\"platform\", columns=\"group\", values=\"arpu\")\n",
    "arppu_pivot = metrics_total.pivot(index=\"platform\", columns=\"group\", values=\"arppu\")\n",
    "with pd.ExcelWriter(excel_path) as writer:\n",
    "    arpu_pivot.to_excel(writer, sheet_name=\"ARPU\")\n",
    "    arppu_pivot.to_excel(writer, sheet_name=\"ARPPU\")\n",
    "    metrics_total.to_excel(writer, sheet_name=\"Metrics_Total\", index=False)\n",
    "\n",
    "print(f\"[Export] metrics_daily → {metrics_daily_path}\")\n",
    "print(f\"[Export] metrics_total → {metrics_total_path}\")\n",
    "print(f\"[Export] metrics_ci → {metrics_ci_path}\")\n",
    "print(f\"[Export] user_level_clean → {user_level_path}\")\n",
    "print(f\"[Export] ARPU/ARPPU_by_group_platform.xlsx → {excel_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
